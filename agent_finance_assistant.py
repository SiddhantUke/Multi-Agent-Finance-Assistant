# -*- coding: utf-8 -*-
"""Agent FInance Assistant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RV6gjaljWbblpdhxPy6nxhY7jxaghCWB
"""

import yfinance as yf

import requests
from bs4 import BeautifulSoup

!pip install faiss-cpu

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
!pip install ctransformers
!pip install git+https://github.com/openai/whisper.git

import yfinance as yf

def get_asia_tech_data():
    tickers = ['TSM', '005930.KS']  # TSMC, Samsung
    data = {}
    for ticker in tickers:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="2d")
        change = (hist['Close'].iloc[-1] - hist['Close'].iloc[-2]) / hist['Close'].iloc[-2] * 100
        data[ticker] = {'latest': hist['Close'].iloc[-1], 'change_%': round(change, 2)}
    return data

"""

---



---

"""

import requests
from bs4 import BeautifulSoup

def scrape_earnings_news():
    url = "https://www.reuters.com/markets/earnings/"
    html = requests.get(url).text
    soup = BeautifulSoup(html, "html.parser")
    articles = soup.select("article h3 a")
    return [a.get_text() for a in articles[:5]]

"""

---



---

"""



# pip install faiss-cpu

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

model = SentenceTransformer('all-MiniLM-L6-v2')
index = faiss.IndexFlatL2(384)
data_chunks = []

def build_index(texts):
    global data_chunks
    data_chunks = texts
    embeddings = model.encode(texts)
    index.add(np.array(embeddings))

def retrieve(query, top_k=3):
    query_vec = model.encode([query])
    D, I = index.search(np.array(query_vec), top_k)
    return [data_chunks[i] for i in I[0]]



"""

---



---

"""

def analyze_risk(market_data):
    asia_exposure = (market_data['TSM']['latest'] + market_data['005930.KS']['latest']) * 1000
    return f"Asia Tech Exposure: {asia_exposure:.2f} USD"

"""

---



---

"""

# pip install ctransformers

from ctransformers import AutoModelForCausalLM

llm = AutoModelForCausalLM.from_pretrained(
    "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
    model_file="mistral-7b-instruct-v0.1.Q4_K_M.gguf",
    model_type="mistral"
)

def generate_response(query, context=""):
    prompt = f"[INST] {context}\n{query} [/INST]"
    return llm(prompt)

"""

---



---

"""

# !pip install git+https://github.com/openai/whisper.git

pip install gTTS

import whisper
# !pip install gTTS
from gtts import gTTS
import os

asr = whisper.load_model("base")

def speech_to_text(audio_path):
    result = asr.transcribe(audio_path)
    return result['text']

def text_to_speech(text, out_path="output.mp3"):
    tts = gTTS(text)
    tts.save(out_path)
    os.system(f"start {out_path}")

"""

---



---

"""

from agents.api_agent import get_asia_tech_data
from agents.scraping_agent import scrape_earnings_news
from agents.retriever_agent import build_index, retrieve
from agents.analysis_agent import analyze_risk
from agents.language_agent import generate_response

def run_pipeline(query):
    market_data = get_asia_tech_data()
    headlines = scrape_earnings_news()
    risk_report = analyze_risk(market_data)

    context = f"{headlines}\n{risk_report}\n{market_data}"
    build_index([context])
    top_chunks = retrieve(query)

    return generate_response(query, "\n".join(top_chunks))

!pip install -q streamlit

!pip install py-orchestrator





pip install multi-agent-orchestrator

from orchestrator.main_orchestrator import run_pipeline

# !pip install -q streamlit
# !pip install py-orchestrator

pip install streamlit py-orchestrator gTTS

pip install streamlit py-orchestrator gTTS

# !pip install -q streamlit
# !pip install py-orchestrator
# !pip install gTTS

import streamlit as st
from orchestrator.main_orchestrator import run_pipeline
# from gtts import gTTS
from agents.voice_agent import text_to_speech

st.title("Morning Market Brief Assistant")

query = st.text_input("Ask your query:")
if st.button("Run Agent"):
    result = run_pipeline(query)
    st.write(result)
    text_to_speech(result)







